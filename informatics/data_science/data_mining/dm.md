# Data Mining

`2020, Dec. 1st, Jaroslav Langer`

## Contents <!-- omit in toc -->
- [Decision Tree](#decision-tree)
- [Ensemble Methods (Random Forests, Ada Boost)](#ensemble-methods-random-forests-ada-boost)
- [Hierarchical Clustering (Agglomerative Clustering, Ward Method)](#hierarchical-clustering-agglomerative-clustering-ward-method)
- [K-Means](#k-means)
- [K-Nearest Neighbors](#k-nearest-neighbors)
- [Naive Bayes](#naive-bayes)
- [Linear Regression](#linear-regression)
- [Ridge Regression](#ridge-regression)
- [Dimensionality Reduction (SVD, PCA, LLE)](#dimensionality-reduction-svd-pca-lle)
  - [Singular Value Decomposition](#singular-value-decomposition)
  - [Principle Component Analysis (PCA)](#principle-component-analysis-pca)
  - [Locally Linear Embedding (Manifold Learning)](#locally-linear-embedding-manifold-learning)
- [Neural Networks (NN/ANN)](#neural-networks-nnann)
  - [Multilayer Perceptron (MLP)](#multilayer-perceptron-mlp)
  - [Convolutional Neural Networks (CNN)](#convolutional-neural-networks-cnn)
  - [Recurrent Neural Networks (RNN)](#recurrent-neural-networks-rnn)

## Decision Tree

## Cross Entropy Loss

- [cross_entropy_loss (gombru.github.io)](https://gombru.github.io/2018/05/23/cross_entropy_loss/)

## Ensemble Methods (Random Forests, Ada Boost)

## Hierarchical Clustering (Agglomerative Clustering, Ward Method)

## K-Means

## K-Nearest Neighbors

## Naive Bayes

## Linear Regression

## Ridge Regression

## Dimensionality Reduction (SVD, PCA, LLE)

### Singular Value Decomposition

### Principle Component Analysis (PCA)

### Locally Linear Embedding (Manifold Learning)

## Neural Networks (NN/ANN)

### Multilayer Perceptron (MLP)

### Convolutional Neural Networks (CNN)

### Recurrent Neural Networks (RNN)
