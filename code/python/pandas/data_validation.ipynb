{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Data Validation\n",
    "\n",
    "## Imports"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "source": [
    "## Get dataframe\n",
    "\n",
    "[Inspired by Simple Example Dataframes In pandas (chrisalbon.com)](https://chrisalbon.com/python/data_wrangling/pandas_dataframe_examples/)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import choice, randrange, uniform\n",
    "\n",
    "NAMES =             ['Jason', 'Molly', 'Tina', 'Jake', 'Amy']\n",
    "SURNAMES =          ['Miller', 'Jacobson', 'Ali', 'Milner', 'Cooze']\n",
    "MISSING_VALUES =    [0, None, float(\"nan\"), '', '-', '?', 'N']\n",
    "LEN = 100\n",
    "\n",
    "COLUMNS = ['first_name', 'last_name', 'age', 'score', 'empty_values', 'mixed']\n",
    "\n",
    "df_list = [[\n",
    "    choice(NAMES), \n",
    "    choice(SURNAMES),\n",
    "    randrange(0, 101, 1),\n",
    "    round(uniform(0, 10), randrange(0, 4, 1)),\n",
    "    choice(MISSING_VALUES),\n",
    "    choice([\n",
    "        choice(NAMES), \n",
    "        choice(SURNAMES), \n",
    "        randrange(0, 101, 1), \n",
    "        round(uniform(0, 10), randrange(0, 4, 1)),\n",
    "        choice(MISSING_VALUES)\n",
    "    ])\n",
    "] for x in range(0,LEN)]\n",
    "\n",
    "df = pd.DataFrame(df_list, columns=COLUMNS)\n",
    "\n",
    "df_original = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "   first_name last_name  age  score empty_values  mixed\n20        Amy    Milner   99  9.040          NaN     46\n49      Molly  Jacobson   59  4.390            ?    Ali\n73       Jake  Jacobson   74  3.220            0   Jake\n14       Jake    Miller   29  1.000         None    Amy\n65        Amy    Milner   17  6.000            -      -\n34       Jake    Miller   95  4.920               Cooze\n41       Jake    Milner   89  0.964         None     46\n30      Molly    Milner   35  5.000         None     41\n11       Tina     Cooze   33  0.400            -     21\n31        Amy     Cooze   13  2.629            ?     82",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>first_name</th>\n      <th>last_name</th>\n      <th>age</th>\n      <th>score</th>\n      <th>empty_values</th>\n      <th>mixed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>20</th>\n      <td>Amy</td>\n      <td>Milner</td>\n      <td>99</td>\n      <td>9.040</td>\n      <td>NaN</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>Molly</td>\n      <td>Jacobson</td>\n      <td>59</td>\n      <td>4.390</td>\n      <td>?</td>\n      <td>Ali</td>\n    </tr>\n    <tr>\n      <th>73</th>\n      <td>Jake</td>\n      <td>Jacobson</td>\n      <td>74</td>\n      <td>3.220</td>\n      <td>0</td>\n      <td>Jake</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Jake</td>\n      <td>Miller</td>\n      <td>29</td>\n      <td>1.000</td>\n      <td>None</td>\n      <td>Amy</td>\n    </tr>\n    <tr>\n      <th>65</th>\n      <td>Amy</td>\n      <td>Milner</td>\n      <td>17</td>\n      <td>6.000</td>\n      <td>-</td>\n      <td>-</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>Jake</td>\n      <td>Miller</td>\n      <td>95</td>\n      <td>4.920</td>\n      <td></td>\n      <td>Cooze</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>Jake</td>\n      <td>Milner</td>\n      <td>89</td>\n      <td>0.964</td>\n      <td>None</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>Molly</td>\n      <td>Milner</td>\n      <td>35</td>\n      <td>5.000</td>\n      <td>None</td>\n      <td>41</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>Tina</td>\n      <td>Cooze</td>\n      <td>33</td>\n      <td>0.400</td>\n      <td>-</td>\n      <td>21</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>Amy</td>\n      <td>Cooze</td>\n      <td>13</td>\n      <td>2.629</td>\n      <td>?</td>\n      <td>82</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "display(\n",
    "    df.sample(n=10)\n",
    ")"
   ]
  },
  {
   "source": [
    "## Exploration of a feature"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_floats(df, feature):\n",
    "    float_filter = df[feature].apply(lambda x: isinstance(x, float))\n",
    "    float_num = float_filter.sum()\n",
    "    float_nan = df[float_filter][feature].isnull().sum()\n",
    "    float_dec = df[float_filter][feature].notnull().sum()\n",
    "    row_num = df.shape[0]\n",
    "    print(f\"Float values - number of floats: {float_num} (~ {float_num/row_num*100:.2f}% of rows)\",\n",
    "        f\"nan values: {float_nan} (~ {float_nan/float_num*100:.2f}% of floats ~ {float_nan/row_num*100:.2f}% of rows)\",\n",
    "        f\"Decimal numbers: {float_dec} (~ {float_dec/float_num*100:.2f}% of floats)\\n\", sep=\"\\n\"\n",
    "    )\n",
    "    return None\n",
    "\n",
    "def explore_strings(df, feature):\n",
    "    string_filter = df[feature].apply(lambda x: isinstance(x, str))\n",
    "    string_number = string_filter.sum()\n",
    "    string_numeric = df[string_filter][feature].str.isnumeric().sum()\n",
    "    string_oth = (~df[string_filter][feature].str.isnumeric()).sum()\n",
    "    row_num = df.shape[0]\n",
    "    print(f\"String values - number of string values: {string_number} (~ {string_number/row_num*100:.2f}% of rows)\",\n",
    "            f\"Numeric strings: {string_numeric} (~ {string_numeric/string_number*100:.2f}% of strings)\",\n",
    "            f\"Other strings: {string_oth} (~ {string_oth/string_number*100:.2f}% of strings)\\n\", sep=\"\\n\"\n",
    "    )\n",
    "    print(\"Number of unique other strings: {}, the strings: {}\\n\".format(\n",
    "        df[string_filter][(~df[string_filter][feature].str.isnumeric())][feature].nunique(),\n",
    "        df[string_filter][(~df[string_filter][feature].str.isnumeric())][feature].unique()\n",
    "    ))\n",
    "    return None\n",
    "\n",
    "def explore_other(df, feature, feature_type):\n",
    "    none_filter = df[feature].apply(lambda x: isinstance(x, feature_type))\n",
    "    none_number = none_filter.sum()\n",
    "    row_num = df.shape[0]\n",
    "    print(\"{} values - number: {} (~ {:.2f}% of rows)\\n\".format(\n",
    "        feature_type, none_number, none_number/row_num*100\n",
    "    ))\n",
    "\n",
    "\n",
    "def explore_feature(df, feature):\n",
    "    print(\"Number of rows: {}\\nNumber of unique values (nan included): {}\\n\".format(\n",
    "        df.shape[0], df[feature].nunique(False)\n",
    "    ))\n",
    "\n",
    "    display(\"Sample of how the values look like:\",\n",
    "        df[feature].sample(n=10)\n",
    "    )\n",
    "    # print(f\"Type of \\\"{feature}\\\" feature: {df.dtypes[feature]}\\n\")\n",
    "\n",
    "    value_types = df[feature].apply(lambda x: type(x)).unique()\n",
    "    print(f\"Value types: {value_types}\\n\")\n",
    "\n",
    "    for value_type in value_types:\n",
    "        if (value_type is float):\n",
    "            explore_floats(df, feature)\n",
    "        elif (value_type is str):\n",
    "            explore_strings(df, feature)\n",
    "        else:\n",
    "            explore_other(df, feature, value_type)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of rows: 100\nnumber of unique values (nan included) 7\n\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "'Sample of how the values look like:'"
     },
     "metadata": {}
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "4        0\n7      NaN\n77    None\n78       ?\n54       N\n16       ?\n17       N\n97     NaN\n26       N\n2        0\nName: empty_values, dtype: object"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Value types: [<class 'str'> <class 'NoneType'> <class 'int'> <class 'float'>]\n\nString values - number of string values: 56 (~ 56.00% of rows)\nnumeric strings: 0 (~ 0.00% of strings)\nother strings: 56 (~ 100.00% of strings)\n\nNumber of unique other strings: 4, the strings: ['' '-' '?' 'N']\n\n<class 'NoneType'> values - number: 16 (~ 16.00% of rows)\n\n<class 'int'> values - number: 13 (~ 13.00% of rows)\n\nFloat values - number of floats: 15 (~ 15.00% of rows)\nnan values: 15 (~ 100.00% of floats)\ndecimal numbers: 0 (~ 0.00% of floats)\n\n"
     ]
    }
   ],
   "source": [
    "df = df_original\n",
    "feature = \"empty_values\"\n",
    "\n",
    "explore_feature(df, feature)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# display(\"Number of floats (that are not nan): {}\".format(\n",
    "#     (df[FEATURE].apply(lambda x: type(x) == float) & df[FEATURE].notnull()).sum()\n",
    "# ))\n",
    "\n",
    "\n",
    "# df[FEATURE].unique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "Cannot take a larger sample than population when 'replace=False'",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d8d7b06cc591>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m display(\"Sample of how the values looks like:\",\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFEATURE\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n\u001b[1;32m      6\u001b[0m display(\"Type of \\\"{}\\\" feature: {}\".format(\n",
      "\u001b[0;32m~/.langerenv_0.2/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n, frac, replace, weights, random_state, axis)\u001b[0m\n\u001b[1;32m   5059\u001b[0m             )\n\u001b[1;32m   5060\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5061\u001b[0;31m         \u001b[0mlocs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis_length\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5062\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5063\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmtrand.pyx\u001b[0m in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot take a larger sample than population when 'replace=False'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "display(\"Number of null values: {} ~ {:.2f}%\".format(\n",
    "    df[FEATURE].isnull().sum(), df[FEATURE].isnull().sum() / df.shape[0] * 100\n",
    "))\n",
    "display(\"Number of \\\"real\\\" values (not null): {} ~ {:.2f}%\".format(\n",
    "    df[FEATURE].notnull().sum(), df[FEATURE].notnull().sum() / df.shape[0] * 100\n",
    "))\n",
    "display(\"Number of integers: {}\".format(\n",
    "    (df[FEATURE].apply(lambda x: type(x) == int) & df[FEATURE].notnull()).sum()\n",
    "))\n",
    "display(\"Number of string values comprehensible as a number: {} (regex), same as {} (str.isnumeric)\".format((\n",
    "        df[FEATURE].str.match(r\"\\d+(\\.\\d+)*\\Z\")==True).sum(),\n",
    "        df[FEATURE].str.isnumeric().sum()\n",
    "))\n",
    "display(f\"\"\"String values that can not be understood as a number, row count: {\n",
    "        (df[FEATURE].str.isnumeric()==False).sum()\n",
    "    }\"\"\", f\"\"\"list of unique values: {\n",
    "        df[df[FEATURE].apply(lambda x: type(x) == str) & ~(df[FEATURE].str.isnumeric()==True)][FEATURE].unique()}\"\"\"\n",
    ")\n",
    "display(f\"Histogram of \\\"{FEATURE}\\\" values:\")\n",
    "fig = px.histogram(df, x=FEATURE)\n",
    "fig.show()\n",
    "fig.write_image(f\"figures/{FEATURE.lower().replace(' ', '_')}.png\")"
   ]
  }
 ]
}